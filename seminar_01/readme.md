# Домашнее задание: Семинар 1

В этом задании представлены 6 задач по проектированию архитектур нейросетей. Каждая задача включает **условия на архитектуру** и **экспериментальные наблюдения**, которые необходимо выполнить.

---

## Вариант 1

**Цель:** Контроль дисперсии весов.

- Разработайте архитектуру, которая будет за **5 слоев** приводить тензор к размерности `(1, 512, 1, 1)`.
- **Условие:** дисперсия весов третьего слоя должна быть в **два раза больше**, чем у второго и четвертого.
- **Эксперимент:** Проверьте влияние увеличенной дисперсии третьего слоя на распределение активаций после GAP и визуализируйте их гистограмму.

---

## Вариант 2

**Цель:** Контроль пространственных размерностей через свертки и пулинг.

- Спроектируйте сеть для выхода `(64, 16, 16)` за **не более 3 слоев свертки**.
- **Условие:** Используйте как минимум один слой с `padding=0`, чтобы часть пространственной информации была потеряна. Можно менять в таких условиях kernel_size и stride.
- **Эксперимент:** Сравните выход с использованием `padding=0` и `padding=1`, оцените разницу в размерности и среднее значение активаций.

---

## Вариант 3. Контроль количества параметров

**Цель:** Создание компактной сети.

- Создайте архитектуру, используя **не более 50 000 параметров**.
- **Условие:** Один слой должен быть **1x1 сверткой**, чтобы уменьшить число каналов.
- **Эксперимент:** Подсчитайте количество параметров каждого слоя и убедитесь, что общая сумма не превышает лимита.

---

## Вариант 4. Сравнение GAP и Flatten

**Цель:** Понимание различий между Flatten и Global Average Pooling.

- Спроектируйте сеть с 3 свёрточными слоями, после которых выходной тензор `(batch, 128, 8, 8)`.
- **Условие:** Реализуйте два варианта классификации:
  1. `Flatten → Linear`
  2. `Global Average Pooling → Linear`
- **Эксперимент:** Обучите оба варианта на данных и сравните дисперсию выходных активаций перед финальным слоем.

---

## Вариант 5. Контроль градиентов через глубину

**Цель:** Изучение поведения градиентов в глубокой сети.

- Разработайте сеть с **не менее 6 слоев**, которая выводит тензор `(batch, 64, 8, 8)`.
- **Условие:** Слои должны чередоваться между `Conv2d` и `ReLU`, при этом **градиенты первого слоя должны быть меньше градиентов последнего** после одной итерации `backward()` на случайных данных.
- **Эксперимент:** Визуализируйте градиенты по слоям и объясните, почему градиенты убывают или растут.

---

## Вариант 6. Использование разных типов пулинга

**Цель:** Сравнение MaxPool и Global Average Pooling.

- Спроектируйте сеть для входа `(3, 64, 64)` и выхода `(32, 8, 8)`.
- **Условие:** В сети обязательно должны быть **и `MaxPool2d`, и `AdaptiveAvgPool2d`**.
- **Эксперимент:** Сравните выходы после MaxPool и GAP на одном и том же случайном тензоре, визуализируйте карты признаков и среднее значение активаций.
